{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload the modules before running the program\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import RFData, CameraData, SignalDataset, FuseDatasets\n",
    "import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "data_path = \"E:\\OSA_project\\OSA_project\\Datasets\\osa_new_processed\"\n",
    "# trial_folders = [\"v_12_5\", \"v_13_5\", \"v_13_10\"]\n",
    "trial_folders = os.listdir(data_path)\n",
    "\n",
    "train_idxs = np.linspace(0, 49, 50, dtype=int)\n",
    "train_folders = [trial_folders[i] for i in train_idxs]\n",
    "test_folders = [trial_folders[i] for i in range(len(trial_folders)) if i not in train_idxs]\n",
    "\n",
    "\n",
    "thermal_file_name = \"Thermal_Camera\"\n",
    "num_samps_oversample = 20 # per experiment, number of samples to generate\n",
    "data_length = 9000\n",
    "fs = 30\n",
    "out_len = 1800 # sample length generated\n",
    "thermal_ext = \".tiff\"\n",
    "\n",
    "dataset_thermal_train = CameraData(data_path, train_folders, thermal_file_name, num_samps_oversample, fs, data_length, out_len, thermal_ext)\n",
    "dataset_thermal_test = CameraData(data_path, test_folders, thermal_file_name, num_samps_oversample, fs, data_length, out_len, thermal_ext)\n",
    "\n",
    "samp_f=5e6\n",
    "freq_slope=60.012e12\n",
    "samples_per_chirp=256\n",
    "num_tx = 3\n",
    "num_rx = 4\n",
    "radar_file_name = \"FMCW_Radar.npy\"\n",
    "window_size = 5 # number of range bins to use\n",
    "\n",
    "dataset_radar_train = RFData(data_path, train_folders, data_length, radar_file_name, out_len, window_size, samples_per_chirp, samp_f, freq_slope, num_samps_oversample, num_tx, num_rx, fs)\n",
    "dataset_radar_test = RFData(data_path, test_folders, data_length, radar_file_name, out_len, window_size, samples_per_chirp, samp_f, freq_slope, num_samps_oversample, num_tx, num_rx, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "vital_dict_file_name = \"gt_dict.pkl\"\n",
    "vital_key_radar = \"CHEST\"\n",
    "vital_key_thermal = \"AIR_flow\"\n",
    "l_freq_bpm = 5\n",
    "u_freq_bpm = 30\n",
    "dataset_OSA_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'OSA', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_CSA_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'CSA', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_hypopnea_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'Hypopnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_partial_apnea_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'Partial_Apnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_gt_thermal_train = SignalDataset(data_path, train_folders, vital_dict_file_name, vital_key_thermal, data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "dataset_gt_radar_train = SignalDataset(data_path, train_folders, vital_dict_file_name, vital_key_radar, data_length, out_len, True, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "\n",
    "# dataset_apnea_test = SignalDataset(data_path, test_folders, vital_dict_file_name, 'Sleep_Apnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "#                               normalize=False)\n",
    "# dataset_gt_thermal_test = SignalDataset(data_path, test_folders, vital_dict_file_name, vital_key_thermal, data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "# dataset_gt_radar_test = SignalDataset(data_path, test_folders, vital_dict_file_name, vital_key_radar, data_length, out_len, True, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "fused_dataset_train = FuseDatasets([dataset_radar_train, dataset_thermal_train, dataset_gt_radar_train, dataset_gt_thermal_train, dataset_apnea_train, dataset_hypopnea_train, dataset_partial_apnea_train], [\"radar\", \"thermal\", \"gt_radar\", \"gt_ir\", \"gt_apnea\", \"hypopnea\", \"partial_apnea\"], out_len=out_len)\n",
    "# fused_dataset_test = FuseDatasets([dataset_radar_test, dataset_thermal_test, dataset_gt_radar_test, dataset_gt_thermal_test, dataset_apnea_test], [\"radar\", \"thermal\", \"gt_radar\", \"gt_ir\", \"gt_apnea\"], out_len=out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"E:\\OSA_project\\Emir_Clean\\pre_load_datav2\"\n",
    "\n",
    "gt_OSA = np.load(os.path.join(save_path,r\"gt_OSA.npy\"))\n",
    "gt_CSA  = np.load(os.path.join(save_path,r\"gt_CSA.npy\"))\n",
    "thermal_arr = np.load(os.path.join(save_path,r\"thermal_arr.npy\"))\n",
    "# np.load(os.path.join(save_path,r\"thermal_vid_arr.npy\")_vid_arr)\n",
    "gt_hypopnea = np.load(os.path.join(save_path,r\"gt_hypopnea.npy\"))\n",
    "radar_arr = np.load(os.path.join(save_path,r\"radar_arr.npy\"))\n",
    "gt_radar = np.load(os.path.join(save_path,r\"gt_radar_arr.npy\"))\n",
    "gt_ir = np.load(os.path.join(save_path,r\"gt_ir_arr.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8269230769230769\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "apnea_idx = []\n",
    "folds = []\n",
    "count = 0\n",
    "for i in range(len(gt_OSA)):\n",
    "    # print(i)\n",
    "    try:\n",
    "        # folds.append(gt_OSA.trial_folders[gt_OSA.oversampling_idxs[i][0]])\n",
    "        batch = gt_OSA[i]\n",
    "        if(np.mean(batch) > 0.1):\n",
    "            apnea_idx.append(i)\n",
    "    except:\n",
    "        # print(gt_OSA.trial_folders[dataset_OSA_train.oversampling_idxs[i][0]])\n",
    "        count = count + 1\n",
    "        pass\n",
    "\n",
    "print(100*len(apnea_idx)/len(gt_OSA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUKS_idx = np.load(r\"K:\\OSA_project\\Kai_data\\NUKS_idx.npy\")\n",
    "mode_lock_idx = np.load(r\"K:\\OSA_project\\Kai_data\\mode_lock_idx.npy\")\n",
    "movement_idx = np.load(r\"K:\\OSA_project\\Kai_data\\combined_movement_idx.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_apnea = np.load(r\"K:\\OSA_project\\Emir_Clean\\pre_load_data\\gt_apnea.npy\")\n",
    "gt_hypopnea = np.load(r\"K:\\OSA_project\\Emir_Clean\\pre_load_data\\gt_hypopnea.npy\")\n",
    "gt_ir = np.load(r\"K:\\OSA_project\\Emir_Clean\\pre_load_data\\gt_ir_arr.npy\")\n",
    "gt_radar = np.load(r\"K:\\OSA_project\\Emir_Clean\\pre_load_data\\gt_radar_arr.npy\")\n",
    "radar_arr = np.load(r\"K:\\OSA_project\\Emir_Clean\\pre_load_data\\radar_arr.npy\")\n",
    "thermal_arr = np.load(r\"K:\\OSA_project\\Emir_Clean\\pre_load_data\\thermal_arr.npy\")\n",
    "# thermal_vid_arr = np.load(r\"E:\\OSA_project\\Emir_Clean\\thermal_vid_arr.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_arr = np.linspace(0, 1800/30, 1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(thermal, dmin, dmax, th, mode='max', percentage=25, plot=False):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    thermal: 1d-array, thermal signal\n",
    "    dmin, dmax: int, optional, size of chunks\n",
    "    th: float, threshold value\n",
    "    mode: str, optional, mode of thresholding\n",
    "    Output:\n",
    "    pred: 1d-array, binary prediction\n",
    "    \"\"\"\n",
    "    t_arr = np.linspace(0, len(thermal)/30, len(thermal))\n",
    "    lmin, lmax = utils.hl_envelopes_idx(thermal, dmin=dmin, dmax=dmax)\n",
    "    max_th = np.interp(t_arr, t_arr[lmax], thermal[lmax])\n",
    "    min_th = np.interp(t_arr, t_arr[lmin], thermal[lmin])\n",
    "\n",
    "    if(plot == True):\n",
    "        plt.plot(t_arr, thermal, color='black', label='Thermal Image Signal')\n",
    "        utils.plot_envelope(t_arr, thermal, lmin, lmax)\n",
    "    pred = None\n",
    "    if(mode == 'max'):\n",
    "        pred = ((max_th - min_th)/max(max_th - min_th) < th).astype(int)\n",
    "    elif(mode == '90th'):\n",
    "        pred = ((max_th - min_th)/np.percentile(max_th - min_th, 90) < th).astype(int)\n",
    "    elif(mode == 'median'):\n",
    "        pred = ((max_th - min_th)/np.median(max_th - min_th) < th).astype(int)\n",
    "    elif(mode == 'mean'):\n",
    "        pred = ((max_th - min_th)/np.mean(max_th - min_th) < th).astype(int)\n",
    "    else:\n",
    "        pred = ((max_th - min_th)/np.percentile(max_th - min_th, percentage) < th).astype(int)\n",
    "    return pred, max_th, min_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_movement_peaks(dists_min, dists_max, t_arr, th, x_th, lmin, lmax):\n",
    "    t_arr_min = t_arr[lmin]\n",
    "    idx_min = []\n",
    "    x_min = []\n",
    "    y_min = []\n",
    "\n",
    "    for i in range(len(dists_min)):\n",
    "        if(dists_min[i] > th):\n",
    "            idx_min.append(lmin[i])\n",
    "            x_min.append(t_arr_min[i])\n",
    "            y_min.append(dists_min[i])\n",
    "    \n",
    "    center_list_min = []\n",
    "    iter = 0\n",
    "    while((len(x_min) != 0) and (iter < len(y_min))):\n",
    "        offset = 1\n",
    "        avg_pos_arr = [(x_min[iter], y_min[iter], idx_min[iter])]\n",
    "        while(((iter + offset) < len(y_min)) and (abs(x_min[iter] - x_min[iter+offset]) < x_th)):\n",
    "            avg_pos_arr.append((x_min[iter+offset], y_min[iter+offset], idx_min[iter+offset]))\n",
    "            offset += 1\n",
    "        \n",
    "        centers = []\n",
    "        for xy in avg_pos_arr:\n",
    "            x_min.remove(xy[0])\n",
    "            y_min.remove(xy[1])\n",
    "            idx_min.remove(xy[2])\n",
    "            centers.append(xy[2])\n",
    "        center_list_min.append(np.median(centers)) # can change this to be the mean\n",
    "\n",
    "    t_arr_max = t_arr[lmax]\n",
    "    idx_max = []\n",
    "    x_max = []\n",
    "    y_max = []\n",
    "\n",
    "    for i in range(len(dists_max)):\n",
    "        if(dists_max[i] > th):\n",
    "            idx_max.append(lmax[i])\n",
    "            x_max.append(t_arr_max[i])\n",
    "            y_max.append(dists_max[i])\n",
    "    \n",
    "    center_list_max = []\n",
    "    iter = 0\n",
    "    while((len(x_max) != 0) and (iter < len(y_max))):\n",
    "        offset = 1\n",
    "        avg_pos_arr = [(x_max[iter], y_max[iter], idx_max[iter])]\n",
    "        while(((iter + offset) < len(y_max)) and (abs(x_max[iter] - x_max[iter+offset]) < x_th)):\n",
    "            avg_pos_arr.append((x_max[iter+offset], y_max[iter+offset], idx_max[iter+offset]))\n",
    "            offset += 1\n",
    "        \n",
    "        centers = []\n",
    "        for xy in avg_pos_arr:\n",
    "            x_max.remove(xy[0])\n",
    "            y_max.remove(xy[1])\n",
    "            idx_max.remove(xy[2])\n",
    "            centers.append(xy[2])\n",
    "        center_list_max.append(np.median(centers)) # can change this to be the mean\n",
    "    # print(\"Center List Max: \", center_list_max, '\\n')\n",
    "    # print(\"Center List Min: \", center_list_min, '\\n')\n",
    "    for i in range(len(center_list_max)):\n",
    "        t = t_arr[int(center_list_max[i])]\n",
    "        for j in range(len(center_list_min)):\n",
    "            # print(\"t: \", t, \"t_arr: \", t_arr[int(center_list_min[j])], '\\n')\n",
    "            # print(abs(t - t_arr[int(center_list_min[j])]), x_th, '\\n')\n",
    "            if((len(center_list_min) != 0) and (abs(t - t_arr[int(center_list_min[j])]) < x_th/30)):\n",
    "                center_list_min.remove(center_list_min[j])\n",
    "                break\n",
    "    center_list_max.extend(center_list_min)\n",
    "\n",
    "    return center_list_max\n",
    "    \n",
    "def remove_peaks(center_list, sig, half_length=90):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    center_list: list, indices of peaks\n",
    "    sig: 1d-array, signal\n",
    "    Output:\n",
    "    sig: 1d-array, signal with peaks removed\n",
    "    \"\"\"\n",
    "    signal_comps = []\n",
    "    last_lower = -1\n",
    "    for i in range(len(center_list)):\n",
    "        cut_center = int(center_list[i])\n",
    "        lower = max(0, cut_center-half_length)\n",
    "        upper = min(len(sig), cut_center+half_length)\n",
    "        # print(\"lower: \", lower, \"upper: \", upper, '\\n')\n",
    "        if(i == 0):\n",
    "            signal_comps.append([sig[:lower], [0, lower]])\n",
    "            last_upper = upper\n",
    "        if((i != (len(center_list) - 1)) and (i != 0)):\n",
    "            signal_comps.append([sig[last_upper:lower], [last_upper, lower]])\n",
    "            last_upper = upper\n",
    "        if(i == (len(center_list) - 1)):\n",
    "            signal_comps.append([sig[last_upper:lower], [last_upper, lower]])\n",
    "            signal_comps.append([sig[upper:], [upper, len(sig)]])\n",
    "    return signal_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movement_detector(thermal, dmin=29, dmax=31, th=4.5, plot=False, include_edges=False):\n",
    "\n",
    "    lmin, lmax = utils.hl_envelopes_idx(thermal, dmin=dmin, dmax=dmax)\n",
    "\n",
    "    min_env = thermal[lmin]\n",
    "    max_env = thermal[lmax]\n",
    "    half_len = 4 \n",
    "\n",
    "    dists_min = []\n",
    "    dists_max = []\n",
    "\n",
    "    if(include_edges == True):\n",
    "        start_vec = [(max_env[0]-max_env[1+i])**2 for i in range(half_len)]\n",
    "        start_vec = np.array(start_vec)\n",
    "        dists_max.append(np.sum(start_vec)/((1 or np.mean(start_vec[np.argsort(start_vec)[::-1]]))*len(start_vec)))\n",
    "\n",
    "   \n",
    "    for i in range(1, len(max_env)-1):\n",
    "        vec_start = max(0, i - half_len)\n",
    "        vec_end = min(len(max_env), i + half_len)\n",
    "        vec = max_env[vec_start:vec_end]\n",
    "        vec = np.array(vec)\n",
    "        center_vec = np.repeat(max_env[i], len(vec))\n",
    "        dist = np.sum((center_vec - vec)**2)/((1 or np.mean(vec[np.argsort(vec)[::-1]]))*len(vec))\n",
    "        dists_max.append(dist)\n",
    "\n",
    "    if(include_edges == True):\n",
    "        end_vec = [(max_env[len(max_env)-1]-max_env[len(max_env)-2-i])**2  for i in range(half_len)]\n",
    "        end_vec = np.array(end_vec)\n",
    "        dists_max.append(np.sum(end_vec)/((1 or np.mean(end_vec[np.argsort(end_vec)[::-1]]))*len(end_vec)))\n",
    "\n",
    "        start_vec = [(min_env[0]-min_env[1+i])**2 for i in range(half_len)]\n",
    "        start_vec= np.array(start_vec)\n",
    "        dists_min.append(np.sum(start_vec)/((1 or np.mean(start_vec[np.argsort(start_vec)[::-1]]))*len(start_vec)))\n",
    "\n",
    "    for i in range(1, len(min_env)-1):\n",
    "        vec_start = max(0, i - half_len)\n",
    "        vec_end = min(len(min_env), i + half_len)\n",
    "        vec = min_env[vec_start:vec_end]\n",
    "        vec = np.array(vec)\n",
    "        center_vec = np.repeat(min_env[i], len(vec))\n",
    "        dist = np.sum((center_vec - vec)**2)/((1 or np.mean(vec[np.argsort(vec)[::-1]]))*len(vec))\n",
    "        dists_min.append(dist)\n",
    "\n",
    "    if(include_edges == True):\n",
    "        end_vec = [(min_env[len(min_env)-1]-min_env[len(min_env)-2-i])**2  for i in range(half_len)]\n",
    "        end_vec = np.array(end_vec)\n",
    "        dists_min.append(np.sum(end_vec)/((1 or np.mean(end_vec[np.argsort(end_vec)[::-1]]))*len(end_vec)))\n",
    "\n",
    "    dists_min = np.array(dists_min)\n",
    "    dists_max = np.array(dists_max)\n",
    "    if(plot == True):\n",
    "        t_arr = np.linspace(0, len(thermal)/30, len(thermal))\n",
    "        if(include_edges == True):\n",
    "            lx = t_arr[lmin]\n",
    "            mx = t_arr[lmax]\n",
    "            plt.plot(lx, dists_min)\n",
    "            plt.plot(mx, dists_max)\n",
    "            plt.show()\n",
    "        else:\n",
    "            lx = t_arr[lmin][1:-1]\n",
    "            mx = t_arr[lmax][1:-1]\n",
    "            plt.plot(lx, dists_min)\n",
    "            plt.plot(mx, dists_max)\n",
    "            plt.show()\n",
    "            \n",
    "    # ld, ud = max(dists_min), max(dists_max)\n",
    "    # ld_arr = []\n",
    "    # for ld in dists_min:\n",
    "    #     if(ld > th):\n",
    "    #         ld_arr.append(ld)\n",
    "    \n",
    "    # ud_arr = []\n",
    "    # for ud in dists_max:\n",
    "    #     if(ud > th):\n",
    "    #         ud_arr.append(ud)\n",
    "    \n",
    "    \n",
    "    # print(ld)\n",
    "    # print(ud)\n",
    "    # window = 90\n",
    "\n",
    "    # peaks_min = []\n",
    "    # t_peaks_min = []\n",
    "    # peaks_max = []\n",
    "    # t_peaks_max = []\n",
    "    # for i in range(len(dists_min)):\n",
    "    #     if(dists_min[i] > th):\n",
    "    #         peaks_min.append(i)\n",
    "    #         t_peaks_min.append(t_arr[lmin][i])\n",
    "    \n",
    "    # for i in range(len(dists_max)):\n",
    "    #     if(dists_max[i] > th):\n",
    "    #         peaks.append(i)\n",
    "    #         t_peaks.append(t_arr[lmax][i])\n",
    "        \n",
    "    # # get all points above threshold\n",
    "    # # if there is more than one within 10 second span average their locations and block out  6 seconds worth\n",
    "    # if((ld > th)):\n",
    "    #     remove_idx = np.argmax(dists_min)\n",
    "    #     lx = t_arr[lmin]\n",
    "    #     cut_center = lmin[remove_idx]\n",
    "    #     print(t_arr[cut_center])\n",
    "\n",
    "    #     lower = max(0, cut_center-window)\n",
    "    #     upper = min(len(thermal), cut_center+window)\n",
    "    #     p1 = 1.5*thermal[0:lower]\n",
    "    #     p2 = 1.5*thermal[upper:]\n",
    "    #     plt.figure(figsize=(12,12))\n",
    "    #     plt.plot(t_arr[0:lower], p1)\n",
    "    #     plt.plot(t_arr[upper:], p2)\n",
    "    #     plt.show()\n",
    "    \n",
    "    # if((ud > th)):\n",
    "    #     remove_idx = np.argmax(dists_max)\n",
    "    #     mx = t_arr[lmax]\n",
    "\n",
    "    #     cut_center = lmax[remove_idx]\n",
    "    #     print(t_arr[cut_center])\n",
    "    #     lower = max(0, cut_center-window)\n",
    "    #     upper = min(len(thermal), cut_center+window)\n",
    "    #     p1 = 1.5*thermal[0:lower]\n",
    "    #     p2 = 1.5*thermal[upper:]\n",
    "    #     plt.figure(figsize=(12,12))\n",
    "    #     plt.plot(t_arr[0:lower], p1)\n",
    "    #     plt.plot(t_arr[upper:], p2)\n",
    "    #     plt.show()\n",
    "        # plt.plot(t_arr, thermal)\n",
    "\n",
    "    return(dists_min, dists_max, lmin, lmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='raise')\n",
    "for k in tqdm(range(321,322)):\n",
    "    i = k\n",
    "    radar_signal = radar_arr[i][:,0,0,:,2]\n",
    "    radar_signal = radar_signal[:,0] + 1j*radar_signal[:,1]\n",
    "    radar_signal = np.unwrap(np.angle(radar_signal))\n",
    "    sig_std = np.std(radar_signal)\n",
    "    radar_signal = (radar_signal - np.mean(radar_signal))\n",
    "    \n",
    "    dists_min, dists_max, lmin, lmax = movement_detector(radar_signal, dmin=20, dmax=20, th=20, plot=True)\n",
    "    utils.plot_envelope(t_arr, radar_signal, dmin=20, dmax=20)\n",
    "\n",
    "    center_list = find_movement_peaks(dists_min, dists_max, t_arr, th=15, x_th=150, lmin=lmin, lmax=lmax)\n",
    "    half_length = 90\n",
    "    print('center_list', center_list)\n",
    "    signal_comps = remove_peaks(center_list, radar_signal, half_length=half_length)\n",
    "    print('signal_comps len',len(signal_comps))\n",
    "    pred = np.zeros(len(radar_signal))\n",
    "\n",
    "    plt.plot(t_arr, radar_signal)\n",
    "    plt.show()\n",
    "    print('len', len(signal_comps))\n",
    "    for sig in signal_comps:\n",
    "        if(len(sig[0]) != 0):\n",
    "            print('len(sig[0])', len(sig[0]), 'std(sig[0])', np.std(sig[0]))\n",
    "            new_radar = (sig[0] - np.mean(sig[0]))/np.std(sig[0])\n",
    "            plt.plot(t_arr[sig[1][0]:sig[1][1]], new_radar)\n",
    "            plt.show()\n",
    "            # print('start', sig[1][0], 'finish', sig[1][1], 'len', len(sig))\n",
    "            pred[sig[1][0]:sig[1][1]] = utils.predict(new_radar , dmin=20, dmax=20, th=0.2, mode='max', plot=True)\n",
    "            utils.plot_envelope(t_arr[sig[1][0]:sig[1][1]], new_radar, dmin=20, dmax=20)\n",
    "            plt.show()\n",
    "    if(len(signal_comps) == 0):\n",
    "        pred = utils.predict(radar_signal , dmin=20, dmax=20, th=0.1, mode='max', plot=True)\n",
    "    print('mean(pred)', np.mean(pred))\n",
    "    # for i in range(len(center_list)):\n",
    "    #     cut_center = int(center_list[i])\n",
    "    #     lower = max(0, cut_center-half_length)\n",
    "    #     upper = min(len(pred), cut_center+half_length)\n",
    "    #     pred[lower:upper] = 0\n",
    "\n",
    "    plt.plot(t_arr, gt_apnea[i], label='gt_radar')\n",
    "    plt.plot(t_arr, pred, label='radar')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar2_arr = []\n",
    "for i in tqdm(range(1000)):\n",
    "    radar_signal = radar_arr[i][:,0,0,:,2]\n",
    "    radar_signal = radar_signal[:,0] + 1j*radar_signal[:,1]\n",
    "    radar_signal = np.unwrap(np.angle(radar_signal))\n",
    "    radar_signal = (radar_signal - np.mean(radar_signal)) / np.std(radar_signal)\n",
    "    radar2_arr.append(radar_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7*15*100/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_arr = [20]#np.linspace(0.01, 4, 5)\n",
    "x_th_arr = [240]\n",
    "peak_th = [20]# np.linspace(5, 50, 5)\n",
    "dmax_arr = [29,31]#np.linspace(20,40, 10, dtype=int)\n",
    "\n",
    "full_arr = []\n",
    "prod_arr = []\n",
    "\n",
    "for th in tqdm(th_arr):\n",
    "    for p_th in peak_th:\n",
    "        for dmax in dmax_arr:\n",
    "            for dmin in dmin_arr:\n",
    "                for x_th in x_th_arr:\n",
    "\n",
    "                    gt_arr = []\n",
    "                    pred_arr = []\n",
    "\n",
    "\n",
    "                    for i in range(1000):\n",
    "                        radar_signal = radar2_arr[i]\n",
    "                        dists_min, dists_max, lmin, lmax = movement_detector(radar_signal, dmin=dmin, dmax=dmax, th=p_th, plot=False)\n",
    "                        # utils.plot_envelope(t_arr, radar_signal, dmin=dmin, dmax=dmax)\n",
    "\n",
    "                        center_list = find_movement_peaks(dists_min, dists_max, t_arr, th=15, x_th=x_th, lmin=lmin, lmax=lmax)\n",
    "                        half_length = 90\n",
    "                        # print('center_list', center_list)\n",
    "                        signal_comps = remove_peaks(center_list, radar_signal, half_length=half_length)\n",
    "                        # print('signal_comps len',len(signal_comps))\n",
    "                        pred = np.zeros(len(radar_signal))\n",
    "                        gt = gt_apnea[i]\n",
    "                        # plt.plot(t_arr, radar_signal)\n",
    "                        # plt.show()\n",
    "                        # print('len', len(signal_comps))\n",
    "                        for sig in signal_comps:\n",
    "                            if(len(sig[0]) != 0):\n",
    "                                # print('len(sig[0])', len(sig[0]), 'std(sig[0])', np.std(sig[0]))\n",
    "                                new_radar = (sig[0] - np.mean(sig[0]))/np.std(sig[0])\n",
    "                                # plt.plot(t_arr[sig[1][0]:sig[1][1]], new_radar)\n",
    "                                # plt.show()\n",
    "                                # print('start', sig[1][0], 'finish', sig[1][1], 'len', len(sig))\n",
    "                                pred[sig[1][0]:sig[1][1]] = utils.predict(new_radar , dmin=dmin, dmax=dmax, th=th, mode='max', plot=False)\n",
    "                                # utils.plot_envelope(t_arr[sig[1][0]:sig[1][1]], new_radar, dmin=dmin, dmax=dmax)\n",
    "                                # plt.show()\n",
    "                        if(len(signal_comps) == 0):\n",
    "                            pred = utils.predict(radar_signal , dmin=dmin, dmax=dmax, th=th, mode='max', plot=True)\n",
    "                        # for i in range(len(center_list)):\n",
    "\n",
    "                        if((np.mean(gt) > 0.1)):# or (np.mean(gt_hp) > 0.1)):\n",
    "                            gt_arr.append(1)\n",
    "                        else:\n",
    "                            gt_arr.append(0)\n",
    "                        \n",
    "                        if(np.mean(pred) > 0.1):\n",
    "                            pred_arr.append(1)\n",
    "                        else:\n",
    "                            pred_arr.append(0)\n",
    "                                            \n",
    "                                            # if(gt_arr[-1] != pred_arr[-1]):\n",
    "                                            #     print(idx)\n",
    "                                    \n",
    "                                        \n",
    "                    precision, recall, accuracy, confusion_matrix = utils.get_stats(np.array(pred_arr), np.array(gt_arr))\n",
    "                    full_arr.append([th, dmin, dmax, x_th, precision, recall, accuracy, confusion_matrix])\n",
    "                    prod_arr.append(precision*recall)\n",
    "                    print(r\"##################################################################\\n\")\n",
    "                    print('th: ', th, 'dmin: ', dmin, 'dmax: ', dmax, 'x_th: ', x_th, '\\n')\n",
    "                    print('precision: ', precision, 'recall: ', recall, 'accuracy: ', accuracy, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argsort(prod_arr)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_arr[best_idx[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision, recall, accuracy, confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = movement_idx[0]\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        radar_signal = radar_arr[id][:,i,j,:,2]\n",
    "        radar_signal = radar_signal[:,0] + 1j*radar_signal[:,1]\n",
    "        radar_signal = np.unwrap(np.angle(radar_signal))\n",
    "        radar_signal = (radar_signal - np.mean(radar_signal))/ np.std(radar_signal)\n",
    "        plt.plot(t_arr, radar_signal, label='radar signal')\n",
    "        plt.plot(t_arr, gt_radar[id], label='gt radar signal')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indecies = [240] #[240,241,249,250,251,253,259,295,461]\n",
    "# np.random.choice(1000, 10)\n",
    "# plt.plot(t_arr, thermal_arr[indecies], label='thermal')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(gt_ir[indecies], label='gt_ir')\n",
    "# Thermal \n",
    "# Radar \n",
    "for i in indecies:\n",
    "    radar_signal = radar_arr[i][:,0,0,:,2]\n",
    "    radar_signal = radar_signal[:,0] + 1j*radar_signal[:,1]\n",
    "    radar_signal = np.unwrap(np.angle(radar_signal))\n",
    "    radar_signal = (radar_signal - np.mean(radar_signal))/ np.std(radar_signal)\n",
    "    print(i)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.plot(t_arr, gt_radar[i], label='gt_radar')\n",
    "    plt.plot(t_arr, -radar_signal, label='radar')\n",
    "    plt.plot(t_arr, gt_apnea[i], label='gt_apnea')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(fused_dataset_train))):\n",
    "    if(i in NUKS_idx):\n",
    "        pass\n",
    "        # print(\"NUKS\")\n",
    "    elif(i in mode_lock_idx):\n",
    "        pass\n",
    "        # print(\"Mode Lock\")\n",
    "    elif(i in movement_idx):\n",
    "        if(i not in not_movement):\n",
    "            combined_movement_idx.append(i)\n",
    "  \n",
    "        # print(\"Movement\")\n",
    "        # print('idx: ', i, 'std', vid_std(thermal_vid_arr[i]))\n",
    "        # plt.plot(t_arr, gt_apnea[i])\n",
    "        # plt.plot(t_arr, thermal_arr[i])\n",
    "        # plt.show()\n",
    "    else:\n",
    "        # print(\"Normal\")\n",
    "        if(vid_movement_detector(thermal_vid_arr[i]) == True):\n",
    "            combined_movement_idx.append(i)\n",
    "        #     print('idx: ', i, 'std', vid_std(thermal_vid_arr[i]))\n",
    "        #     plt.plot(t_arr, gt_apnea[i])\n",
    "        #     plt.plot(t_arr, thermal_arr[i])\n",
    "        #     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"E:\\OSA_project\\Kai_data\\combined_movement_idx.npy\", np.array(combined_movement_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_movement_idx) + len(NUKS_idx) + len(mode_lock_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(913,len(fused_dataset_train))):\n",
    "    if((i not in combined_movement_idx) and (i not in NUKS_idx) and (i not in mode_lock_idx)):\n",
    "        print('idx: ', i, 'std', vid_std(thermal_vid_arr[i]))\n",
    "        plt.plot(t_arr, gt_apnea[i])\n",
    "        plt.plot(t_arr, thermal_arr[i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 287\n",
    "thermal = utils.get_thermal(fused_dataset_train[idx], order=5)\n",
    "thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "t_arr = np.linspace(0, len(thermal)/30, len(thermal))\n",
    "lmin, lmax = utils.hl_envelopes_idx(thermal, dmin=30, dmax=20)\n",
    "max_th = np.interp(t_arr, t_arr[lmax], thermal[lmax])\n",
    "min_th = np.interp(t_arr, t_arr[lmin], thermal[lmin])\n",
    "pred = ((max_th - min_th)/max(max_th - min_th) < 0.2).astype(int)\n",
    "gt = fused_dataset_train[idx][\"gt_apnea\"][:,0]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "# pred[len(pred)-60:] = 0\n",
    "utils.plot_classification_waveforms(t_arr, thermal, gt, pred, fused_dataset_train[idx][\"gt_radar\"][:,0])\n",
    "fused_dataset_train[idx][\"hypopnea\"][:,0].shape, fused_dataset_train[idx][\"partial_apnea\"][:,0].shape\n",
    "\n",
    "print(utils.detect_NUKS(thermal))\n",
    "print(utils.detect_mode_lock(fused_dataset_train, idx))\n",
    "utils.plot_envelope(t_arr, thermal, lmin, lmax)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 71\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(t_arr, fused_dataset_train[idx][\"gt_apnea\"][:,0], color='blue', linewidth=4, label='Ground Truth Apnea Signal')\n",
    "plt.plot(t_arr, fused_dataset_train[idx][\"hypopnea\"][:,0], label='Hypopnea')\n",
    "plt.plot(t_arr, fused_dataset_train[idx][\"partial_apnea\"][:,0], label='Partial Apnea')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_2_idx = [\n",
    "    62,\n",
    "    71,\n",
    "    74,\n",
    "    78,\n",
    "    79,\n",
    "    207,\n",
    "    211,\n",
    "    214,\n",
    "    223,\n",
    "    229,\n",
    "    231,\n",
    "    287,\n",
    "    296,\n",
    "    300,\n",
    "    324,\n",
    "    328,\n",
    "    331,\n",
    "    338,\n",
    "    60,\n",
    "    64,\n",
    "    69,\n",
    "    74,\n",
    "    75,\n",
    "    200,\n",
    "    201,\n",
    "    203,\n",
    "    206,\n",
    "    225,\n",
    "    234,\n",
    "    239,\n",
    "    62,\n",
    "    71,\n",
    "    78,\n",
    "    79,\n",
    "    207,\n",
    "    211,\n",
    "    214,\n",
    "    223,\n",
    "    229,\n",
    "    231,\n",
    "    241,\n",
    "    242,\n",
    "    244,\n",
    "    250,\n",
    "    251,\n",
    "    253,\n",
    "    255,\n",
    "    460,\n",
    "    465,\n",
    "    478,\n",
    "    483,\n",
    "    590,\n",
    "    591,\n",
    "    596,\n",
    "    598,\n",
    "    612,\n",
    "    654,\n",
    "    684,\n",
    "    773,\n",
    "    841,\n",
    "    842,\n",
    "    843,\n",
    "    846,\n",
    "    855,\n",
    "    856,\n",
    "    857,\n",
    "    858,\n",
    "    859,\n",
    "    988]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for i in tqdm(range(len(movement_2_idx))):# tqdm(np.linspace(0,999, 1000, dtype=int)):\n",
    "    idx = movement_2_idx[i]\n",
    "    if(utils.movement_detector(thermal_arr[idx]) == True):\n",
    "        acc = acc + 1\n",
    "    elif(vid_movement_detector(thermal_vid_arr[idx]) == True):\n",
    "        acc = acc + 1\n",
    "print((172+acc)/(172 + len(movement_2_idx)))\n",
    "print(acc/len(movement_2_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(thermal_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_idx = np.load(r\"E:\\OSA_project\\Kai_data\\movement_new_idx.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermal = np.mean(thermal_vid_arr[idx], axis=(-2,-1))\n",
    "thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "plt.plot(t_arr, thermal)\n",
    "plt.plot(t_arr, gt_apnea[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in movement_2_idx:\n",
    "    diff_arr = np.diff(thermal_vid_arr[idx], axis=0)\n",
    "    mean_arr = np.std(diff_arr**2, axis=(1,2))\n",
    "    print(idx, np.std(mean_arr))\n",
    "\n",
    "    mean_arr = mean_arr/np.std(mean_arr)\n",
    "    lmin, lmax = utils.hl_envelopes_idx(mean_arr, dmin=29, dmax=31)\n",
    "    utils.plot_envelope(t_arr[:-1], mean_arr, lmin, lmax)\n",
    "\n",
    "    plt.plot(t_arr[:-1] , mean_arr)\n",
    "    plt.show()\n",
    "    thermal = np.mean(thermal_vid_arr[idx], axis=(-2,-1))\n",
    "    thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "    plt.plot(t_arr, thermal)\n",
    "    plt.plot(t_arr, gt_apnea[idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,1], [2,3]])\n",
    "print(a)\n",
    "print(np.diff(a, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 545\n",
    "thermal = utils.get_thermal(fused_dataset_train[idx], order=5)\n",
    "thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "t_arr = np.linspace(0, len(thermal)/30, len(thermal))\n",
    "plt.plot(t_arr, thermal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(thermal_vid_arr[idx]), np.std(thermal_vid_arr[504])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUKS_idx = np.load(r\"E:\\OSA_project\\Kai_data\\NUKS_idx.npy\")\n",
    "mode_lock_idx = np.load(r\"E:\\OSA_project\\Kai_data\\mode_lock_idx.npy\")\n",
    "movement_idx = np.load(r\"E:\\OSA_project\\Kai_data\\movement_idx.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Th: 0.35555556, Mode: mean, Window Size: 26 --> best result so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " np.linspace(20,50, 20, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_apneas(dataset_apnea_train)\n",
    "count_apneas(dataset_apnea_test)\n",
    "len(dataset_apnea_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_arr = []\n",
    "recall_arr = []\n",
    "accuracy_arr = []\n",
    "precision_arr = []\n",
    "confusion_arr = []\n",
    "\n",
    "th_arr = [0.35555556]\n",
    "window_size_arr = [26]\n",
    "modes = ['mean']\n",
    "percentile = 0\n",
    "t_arr = np.linspace(0, 1800/30, 1800)\n",
    "wrong_idx = []\n",
    "for th in th_arr:\n",
    "    for mode in modes:\n",
    "        for window_max in window_size_arr:\n",
    "            for window_min in window_size_arr:\n",
    "                gt_arr = []\n",
    "                pred_arr = []\n",
    "                \n",
    "\n",
    "                for idx in tqdm(np.linspace(0,len(fused_dataset_train)-1,len(fused_dataset_train), dtype=int)):\n",
    "                    if((idx not in NUKS_idx) and (idx not in mode_lock_idx) and ((idx not in movement_idx) or (idx in apnea_idx))):\n",
    "                        # int_psd = utils.get_power_spec(thermal_arr[idx], fs=30, window_length=512, overlap=511)\n",
    "                        # pred = None\n",
    "                        # if(utils.no_apnea(int_psd, threshold=1) == True):\n",
    "                        #     pred = np.zeros(1800)\n",
    "                        # else:\n",
    "                        \n",
    "                        pred = utils.predict(thermal_arr[idx], dmin=window_min, dmax=30, th=th, mode=mode, percentage=percentile, plot=False)\n",
    "\n",
    "                        gt = gt_apnea[idx]\n",
    "\n",
    "                        if(np.mean(gt) > 0.1):\n",
    "                            gt_arr.append(1)\n",
    "                        else:\n",
    "                            gt_arr.append(0)\n",
    "                        \n",
    "                        if(np.mean(pred) > 0.1):\n",
    "                            pred_arr.append(1)\n",
    "                        else:\n",
    "                            pred_arr.append(0)\n",
    "                        \n",
    "                        if(pred_arr[-1] != gt_arr[-1]):\n",
    "                            wrong_idx.append(idx)\n",
    "\n",
    "                        \n",
    "                        \n",
    "                precision, recall, accuracy, confusion_matrix = utils.get_stats(np.array(pred_arr), np.array(gt_arr))\n",
    "                recall_arr.append(recall)\n",
    "                accuracy_arr.append(accuracy)\n",
    "                precision_arr.append(precision)\n",
    "                confusion_arr.append(confusion_matrix)\n",
    "                full_arr.append((th, mode, window_size, recall, precision, accuracy, confusion_matrix))\n",
    "\n",
    "                # print(f\"Th: {th}, Mode: {mode}, Window Size: {window_size}\")\n",
    "                # print(f\"Recall: {recall}, Precision: {precision}, Accuracy: {accuracy}\")\n",
    "                # print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_arr[0], precision_arr[0], accuracy_arr[0], confusion_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_arr[0], precision_arr[0], accuracy_arr[0], confusion_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=2\n",
    "thermal = thermal_arr[wrong_idx[k]]\n",
    "t_arr = np.linspace(0, len(thermal)/30, len(thermal))\n",
    "lmin, lmax = utils.hl_envelopes_idx(thermal, dmin=30, dmax=20)\n",
    "max_th = np.interp(t_arr, t_arr[lmax], thermal[lmax])\n",
    "min_th = np.interp(t_arr, t_arr[lmin], thermal[lmin])\n",
    "pred = ((max_th - min_th)/max(max_th - min_th) < 0.2).astype(int)\n",
    "gt = gt_apnea[wrong_idx[k]]\n",
    "int_psd = utils.get_power_spec(thermal, fs=30, window_length=512, overlap=511)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "# pred[len(pred)-60:] = 0\n",
    "# utils.plot_classification_waveforms(t_arr, thermal, gt, pred, fused_dataset_train[idx][\"gt_radar\"][:,0])\n",
    "# fused_dataset_train[idx][\"hypopnea\"][:,0].shape, fused_dataset_train[idx][\"partial_apnea\"][:,0].shape\n",
    "plt.plot(t_arr, gt, color='blue', linewidth=4, label='Ground Truth Apnea Signal')\n",
    "plt.plot(t_arr, thermal, label='Predicted Apnea Signal')\n",
    "processed = utils.lowpass_filter(thermal, fc=0.3, fs=30, order=5)\n",
    "plt.plot(t_arr, processed, label='Low Pass Filtered Signal')\n",
    "                                  \n",
    "utils.plot_envelope(t_arr, thermal, lmin, lmax)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_arr, processed, label='Low Pass Filtered Signal')\n",
    "plt.plot(t_arr, thermal)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_arr[255:-256], int_psd)\n",
    "plt.plot(t_arr, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = np.array(precision_arr)*np.array(recall_arr)\n",
    "\n",
    "# if array contains nan set that entry to zero\n",
    "for i in range(len(prod)):\n",
    "    if(math.isnan(prod[i])):\n",
    "        prod[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argsort(prod)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_arr[best_idx[0]], recall_arr[best_idx[0]], accuracy_arr[best_idx[0]], confusion_arr[best_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"E:\\OSA_project\\Emir_Clean\\th_arr.npy\", th_arr)\n",
    "np.save(r\"E:\\OSA_project\\Emir_Clean\\window_size_arr.npy\", window_size_arr)\n",
    "np.save(r\"E:\\OSA_project\\Emir_Clean\\modes.npy\", modes)\n",
    "np.save(r\"E:\\OSA_project\\Emir_Clean\\recall_arr.npy\", recall_arr)\n",
    "np.save(r\"E:\\OSA_project\\Emir_Clean\\accuracy_arr.npy\", accuracy_arr)\n",
    "np.save(r\"E:\\OSA_project\\Emir_Clean\\precision_arr.npy\", precision_arr)\n",
    "np.save(r\"E:\\OSA_project\\Emir_Clean\\confusion_arr.npy\", confusion_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(precision_arr)\n",
    "plt.show()\n",
    "plt.plot(recall_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0) come up with hypopnea model\n",
    "# 2.1) implement AHI and other relevant metrics\n",
    "# 2.2) explain model shortcomings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
