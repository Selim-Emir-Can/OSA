{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload the modules before running the program\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import RFData, CameraData, SignalDataset, FuseDatasets\n",
    "import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "data_path = r\"E:\\OSA_project\\OSA_project\\Datasets\\osa_new_processed\"\n",
    "# trial_folders = [\"v_12_5\", \"v_13_5\", \"v_13_10\"]\n",
    "trial_folders = os.listdir(data_path)\n",
    "\n",
    "train_idxs = np.linspace(0, 49, 50, dtype=int)\n",
    "train_folders = [trial_folders[i] for i in train_idxs]\n",
    "test_folders = [trial_folders[i] for i in range(len(trial_folders)) if i not in train_idxs]\n",
    "\n",
    "\n",
    "thermal_file_name = \"Thermal_Camera\"\n",
    "num_samps_oversample = 20 # per experiment, number of samples to generate\n",
    "data_length = 9000\n",
    "fs = 30\n",
    "out_len = 1800 # sample length generated\n",
    "thermal_ext = \".tiff\"\n",
    "\n",
    "dataset_thermal_train = CameraData(data_path, train_folders, thermal_file_name, num_samps_oversample, fs, data_length, out_len, thermal_ext)\n",
    "dataset_thermal_test = CameraData(data_path, test_folders, thermal_file_name, num_samps_oversample, fs, data_length, out_len, thermal_ext)\n",
    "\n",
    "samp_f=5e6\n",
    "freq_slope=60.012e12\n",
    "samples_per_chirp=256\n",
    "num_tx = 3\n",
    "num_rx = 4\n",
    "radar_file_name = \"FMCW_Radar.npy\"\n",
    "window_size = 25 # number of range bins to use\n",
    "\n",
    "dataset_radar_train = RFData(data_path, train_folders, data_length, radar_file_name, out_len, window_size, samples_per_chirp, samp_f, freq_slope, num_samps_oversample, num_tx, num_rx, fs)\n",
    "dataset_radar_test = RFData(data_path, test_folders, data_length, radar_file_name, out_len, window_size, samples_per_chirp, samp_f, freq_slope, num_samps_oversample, num_tx, num_rx, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We don't need the following code block below because the ground truth signals are saved in npy files (assuming seed is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnp.random.seed(0)\\ntorch.manual_seed(0)\\nvital_dict_file_name = \"gt_dict.pkl\"\\nvital_key_radar = \"CHEST\"\\nvital_key_thermal = \"AIR_flow\"\\nl_freq_bpm = 5\\nu_freq_bpm = 30\\ndataset_OSA_train = SignalDataset(data_path, train_folders, vital_dict_file_name, \\'OSA\\', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\\n                              normalize=False)\\ndataset_CSA_train = SignalDataset(data_path, train_folders, vital_dict_file_name, \\'CSA\\', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\\n                              normalize=False)\\ndataset_hypopnea_train = SignalDataset(data_path, train_folders, vital_dict_file_name, \\'Hypopnea\\', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\\n                              normalize=False)\\ndataset_partial_apnea_train = SignalDataset(data_path, train_folders, vital_dict_file_name, \\'Partial_Apnea\\', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\\n                              normalize=False)\\ndataset_gt_thermal_train = SignalDataset(data_path, train_folders, vital_dict_file_name, vital_key_thermal, data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\\ndataset_gt_radar_train = SignalDataset(data_path, train_folders, vital_dict_file_name, vital_key_radar, data_length, out_len, True, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "vital_dict_file_name = \"gt_dict.pkl\"\n",
    "vital_key_radar = \"CHEST\"\n",
    "vital_key_thermal = \"AIR_flow\"\n",
    "l_freq_bpm = 5\n",
    "u_freq_bpm = 30\n",
    "dataset_OSA_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'OSA', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_CSA_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'CSA', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_hypopnea_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'Hypopnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_partial_apnea_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'Partial_Apnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_gt_thermal_train = SignalDataset(data_path, train_folders, vital_dict_file_name, vital_key_thermal, data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "dataset_gt_radar_train = SignalDataset(data_path, train_folders, vital_dict_file_name, vital_key_radar, data_length, out_len, True, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "\"\"\"\n",
    "# dataset_apnea_test = SignalDataset(data_path, test_folders, vital_dict_file_name, 'Sleep_Apnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "#                               normalize=False)\n",
    "# dataset_gt_thermal_test = SignalDataset(data_path, test_folders, vital_dict_file_name, vital_key_thermal, data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "# dataset_gt_radar_test = SignalDataset(data_path, test_folders, vital_dict_file_name, vital_key_radar, data_length, out_len, True, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "# np.random.seed(0)\n",
    "# torch.manual_seed(0)\n",
    "# vital_dict_file_name = \"gt_dict.pkl\"\n",
    "# vital_key_radar = \"CHEST\"\n",
    "# vital_key_thermal = \"AIR_flow\"\n",
    "# l_freq_bpm = 5\n",
    "# u_freq_bpm = 30\n",
    "# dataset_apnea_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'Sleep_Apnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "#                               normalize=False)\n",
    "# dataset_hypopnea_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'Hypopnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "#                               normalize=False)\n",
    "# dataset_partial_apnea_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'Partial_Apnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "#                               normalize=False)\n",
    "# dataset_gt_thermal_train = SignalDataset(data_path, train_folders, vital_dict_file_name, vital_key_thermal, data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "# dataset_gt_radar_train = SignalDataset(data_path, train_folders, vital_dict_file_name, vital_key_radar, data_length, out_len, True, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "\n",
    "# # dataset_apnea_test = SignalDataset(data_path, test_folders, vital_dict_file_name, 'Sleep_Apnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "# #                               normalize=False)\n",
    "# # dataset_gt_thermal_test = SignalDataset(data_path, test_folders, vital_dict_file_name, vital_key_thermal, data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "# # dataset_gt_radar_test = SignalDataset(data_path, test_folders, vital_dict_file_name, vital_key_radar, data_length, out_len, True, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnp.random.seed(0)\\ntorch.manual_seed(0)\\nfused_dataset_train = FuseDatasets([dataset_radar_train, dataset_thermal_train, dataset_gt_radar_train, dataset_gt_thermal_train, dataset_OSA_train, dataset_CSA_train, dataset_hypopnea_train, dataset_partial_apnea_train], [\"radar\", \"thermal\", \"gt_radar\", \"gt_ir\", \"gt_OSA\", \"gt_CSA\", \"hypopnea\", \"partial_apnea\"], out_len=out_len)\\n# fused_dataset_test = FuseDatasets([dataset_radar_test, dataset_thermal_test, dataset_gt_radar_test, dataset_gt_thermal_test, dataset_apnea_test], [\"radar\", \"thermal\", \"gt_radar\", \"gt_ir\", \"gt_apnea\"], out_len=out_len)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "fused_dataset_train = FuseDatasets([dataset_radar_train, dataset_thermal_train, dataset_gt_radar_train, dataset_gt_thermal_train, dataset_OSA_train, dataset_CSA_train, dataset_hypopnea_train, dataset_partial_apnea_train], [\"radar\", \"thermal\", \"gt_radar\", \"gt_ir\", \"gt_OSA\", \"gt_CSA\", \"hypopnea\", \"partial_apnea\"], out_len=out_len)\n",
    "# fused_dataset_test = FuseDatasets([dataset_radar_test, dataset_thermal_test, dataset_gt_radar_test, dataset_gt_thermal_test, dataset_apnea_test], [\"radar\", \"thermal\", \"gt_radar\", \"gt_ir\", \"gt_apnea\"], out_len=out_len)\n",
    "\"\"\"\n",
    "# np.random.seed(0)\n",
    "# torch.manual_seed(0)\n",
    "# fused_dataset_train = FuseDatasets([dataset_radar_train, dataset_thermal_train, dataset_gt_radar_train, dataset_gt_thermal_train, dataset_apnea_train, dataset_hypopnea_train, dataset_partial_apnea_train], [\"radar\", \"thermal\", \"gt_radar\", \"gt_ir\", \"gt_apnea\", \"hypopnea\", \"partial_apnea\"], out_len=out_len)\n",
    "# # fused_dataset_test = FuseDatasets([dataset_radar_test, dataset_thermal_test, dataset_gt_radar_test, dataset_gt_thermal_test, dataset_apnea_test], [\"radar\", \"thermal\", \"gt_radar\", \"gt_ir\", \"gt_apnea\"], out_len=out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"E:\\OSA_project\\Emir_Clean\\pre_load_datav2\"\n",
    "\n",
    "gt_OSA = np.load(os.path.join(save_path,r\"gt_OSA.npy\"))\n",
    "gt_CSA  = np.load(os.path.join(save_path,r\"gt_CSA.npy\"))\n",
    "gt_hypopnea = np.load(os.path.join(save_path,r\"gt_hypopnea.npy\"))\n",
    "gt_radar = np.load(os.path.join(save_path,r\"gt_radar_arr.npy\"))\n",
    "gt_ir = np.load(os.path.join(save_path,r\"gt_ir_arr.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.2\n"
     ]
    }
   ],
   "source": [
    "apnea_idx = []\n",
    "for i in range(len(dataset_apnea_train)):\n",
    "    batch = dataset_apnea_train[i]\n",
    "    if(np.mean(batch) > 0.1):\n",
    "        apnea_idx.append(i)\n",
    "\n",
    "print(100*len(apnea_idx)/len(dataset_apnea_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r\"E:\\OSA_project\\Emir_Clean\\saved_idx_arrs\"\n",
    "NUKS_idx = np.load(os.path.join(root, \"NUKS_idx.npy\"))\n",
    "mode_lock_idx = np.load(os.path.join(root, \"mode_lock_idx.npy\"))\n",
    "combined_movement_idx = np.load(os.path.join(root, \"combined_movement_idx.npy\"))\n",
    "movement_idx = np.load(os.path.join(root, \"movement_new_idx.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r\"E:\\OSA_project\\Emir_Clean\\pre_load_data\"\n",
    "gt_apnea = np.load(os.path.join(root, \"gt_apnea.npy\"))\n",
    "thermal_arr = np.load(os.path.join(root, \"thermal_arr.npy\"))\n",
    "t_arr = np.linspace(0, 1800/30, 1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermal_vid_arr = np.load(os.path.join(root, \"thermal_vid_arr.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_movement_idx = np.load(r\"E:\\OSA_project\\Emir_Clean\\saved_idx_arrs\\gt_movement_idx.npy\")\n",
    "discard_idx = np.load(r\"E:\\OSA_project\\Emir_Clean\\saved_idx_arrs\\discard_idx.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 130.57it/s]\n"
     ]
    }
   ],
   "source": [
    "gt_arr = np.zeros(1000)\n",
    "pred_arr = np.zeros(1000)\n",
    "exp_movement_idx = []\n",
    "# vid_idxs = []\n",
    "id = 10\n",
    "for i in tqdm(range(len(fused_dataset_train))):\n",
    "    if(i in NUKS_idx):\n",
    "        # print(\"NUKS\")\n",
    "        pass\n",
    "    elif(i in mode_lock_idx):\n",
    "        # print(\"Mode Lock\")\n",
    "        pass\n",
    "    elif(i in discard_idx):\n",
    "        # print(\"Discard\")\n",
    "        pass\n",
    "    else:\n",
    "        # print(\"Normal\")\n",
    "        # 3.3684210526315788, 40, 24\n",
    "        if((utils.movement_detector(thermal_arr[i], dmin=dmin_arr[(best_idx[id] % 100) // 10], dmax=dmax_arr[(best_idx[id] % 100) % 10], th=th_arr[best_idx[id] // 100]) == True) or (i in vid_idxs)):\n",
    "            exp_movement_idx.append(i)\n",
    "        \n",
    "        # if(utils.vid_movement_detector(thermal_vid_arr[i], lb=0, ub=200) == True):\n",
    "        #     if(i not in exp_movement_idx):\n",
    "        #         exp_movement_idx.append(i)\n",
    "        #     vid_idxs.append(i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    if(i in gt_movement_idx):\n",
    "        gt_arr[i] = 1\n",
    "    if(i in exp_movement_idx):\n",
    "        pred_arr[i] = 1\n",
    "\n",
    "precision, recall, accuracy, confusion_matrix = utils.get_stats(np.array(pred_arr), np.array(gt_arr))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9532163742690059 0.9421965317919075 0.982 [[163.  10.]\n",
      " [  8. 819.]]\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, accuracy, confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "dmin_arr = np.linspace(15,40, 10, dtype=int)\n",
    "dmax_arr = np.linspace(15,40, 10, dtype=int)\n",
    "th_arr = np.linspace(1, 8, 20)\n",
    "\n",
    "prods = []\n",
    "stats = []\n",
    "fps = []\n",
    "for th in tqdm(th_arr):\n",
    "    for dmin in tqdm(dmin_arr):\n",
    "        for dmax in dmax_arr:\n",
    "            gt_arr = np.zeros(1000)\n",
    "            pred_arr = np.zeros(1000)\n",
    "            exp_movement_idx = []\n",
    "            # exp_movement_idx.extend(vid_idxs)\n",
    "\n",
    "            for i in range(1000):\n",
    "                if(i in NUKS_idx):\n",
    "                    # print(\"NUKS\")\n",
    "                    pass\n",
    "                elif(i in mode_lock_idx):\n",
    "                    # print(\"Mode Lock\")\n",
    "                    pass\n",
    "                elif(i in discard_idx):\n",
    "                    # print(\"Discard\")\n",
    "                    pass\n",
    "                elif(i not in vid_idxs):\n",
    "                    # print(\"Normal\")\n",
    "                    if(utils.movement_detector(thermal_arr[i], dmin=dmin, dmax=dmax, th=th) == True):\n",
    "                        exp_movement_idx.append(i)\n",
    "            \n",
    "            for i in range(1000):\n",
    "                if(i in gt_movement_idx):\n",
    "                    gt_arr[i] = 1\n",
    "                if((i in exp_movement_idx) or (i in vid_idxs)):\n",
    "                    pred_arr[i] = 1\n",
    "\n",
    "            precision, recall, accuracy, confusion_matrix = utils.get_stats(np.array(pred_arr), np.array(gt_arr))\n",
    "            prods.append(precision*recall)\n",
    "            fps.append(confusion_matrix[1,0]) # want to minimize\n",
    "            stats.append([precision, recall, accuracy, confusion_matrix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9640718562874252 0.930635838150289 0.982 [[161.  12.]\n",
      " [  6. 821.]]\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, accuracy, confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if array contains nan set that entry to zero\n",
    "for i in range(len(prods)):\n",
    "    if(math.isnan(prods[i])):\n",
    "        prods[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argsort(prods)[::-1]\n",
    "best_idx = np.array(best_idx, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0\n",
    "th_arr[best_idx[id] // 100], dmin_arr[(best_idx[id] % 100) // 10], dmax_arr[(best_idx[id] % 100) % 10]\n",
    "# (3.3684210526315788, 40, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8640753175729466 [0.9461077844311377, 0.9132947976878613, 0.976, array([[158.,  15.],\n",
      "       [  9., 818.]])]\n"
     ]
    }
   ],
   "source": [
    "print(prods[best_idx[0]], stats[best_idx[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[146.  27.]\n",
      " [  6. 821.]]\n"
     ]
    }
   ],
   "source": [
    "#else\n",
    "print(precision, recall, accuracy, confusion_matrix)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2208994708994709 0.9653179190751445 0.405 [[167.   6.]\n",
      " [589. 238.]]\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, accuracy, confusion_matrix)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(discard_idx)):\n",
    "    index = discard_idx[i]\n",
    "    image_arr = fused_dataset_train[index][\"thermal\"][0,:,:,:]\n",
    "    # thumbnail = f\"E:\\OSA_project\\Kai_data\\{index}.png\"\n",
    "    # plt.imshow(image_arr[0])\n",
    "    # plt.savefig(thumbnail) \n",
    "    norm_im = utils.normalize(image_arr)\n",
    "    # Output video file name\n",
    "    output_video = f\"E:\\OSA_project\\{index}.mp4\"\n",
    "    height, width, = 64, 64\n",
    "    fs = 30\n",
    "\n",
    "    # Create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP42')\n",
    "    video = cv2.VideoWriter(output_video, fourcc, fs, (width, height))\n",
    "\n",
    "    # Iterate over the image files and write each frame to the video\n",
    "    for i in range(len(norm_im)):\n",
    "        img = cv2.applyColorMap(norm_im[i], cv2.COLORMAP_JET)\n",
    "        video.write(img)\n",
    "\n",
    "    # Release the VideoWriter object\n",
    "    video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(900,1000):\n",
    "    if((idx not in NUKS_idx) and (idx not in mode_lock_idx)):\n",
    "        diff_arr = np.diff(thermal_vid_arr[idx], axis=0)\n",
    "        mean_arr = np.std(diff_arr**2, axis=(1,2))\n",
    "        pred = np.mean(utils.predict(thermal_arr[idx], 29, 31, 0.3394, plot=True)) > 0.1\n",
    "        print(idx, np.std(mean_arr), pred)\n",
    "\n",
    "\n",
    "        # mean_arr = mean_arr/np.std(mean_arr)\n",
    "        # lmin, lmax = utils.hl_envelopes_idx(mean_arr, dmin=29, dmax=31)\n",
    "        # utils.plot_envelope(t_arr[:-1], mean_arr, lmin, lmax)\n",
    "\n",
    "        # plt.plot(t_arr[:-1] , mean_arr)\n",
    "        # plt.show()\n",
    "        plt.plot(t_arr, gt_apnea[idx])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 204)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movement_idx), len(combined_movement_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in combined_movement_idx:\n",
    "    if i not in movement_idx:\n",
    "        count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in movement_idx:\n",
    "    if i not in combined_movement_idx:\n",
    "        count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps\n",
    "# 1.1 Re-run grid search for thermal, save optimal parameters and finalize stats w/o motion--> need to wait for motion filtering algorithm (IN PROGRESS)\n",
    "# 1.2 create an algorithm that handles motion --> do this after finishing 1.1\n",
    "\n",
    "# 2.1 create a function that splits indexes based on patient number for AHI metrics -->  DONE\n",
    "\n",
    "# 3.1 make an algorithm for radar and run preliminary results --> can be done immediately\n",
    "\n",
    "# 4.1 create an algorithm that distinguishes between central apnea and obstructive apnea --> waiting for Kai to provide data and waiting to finish radar algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
