{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload the modules before running the program\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import RFData, CameraData, SignalDataset, FuseDatasets\n",
    "import metrics\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "data_path = r\"D:\\osa_new_proc_rev\"\n",
    "# trial_folders = [\"v_12_5\", \"v_13_5\", \"v_13_10\"]\n",
    "trial_folders = os.listdir(data_path)\n",
    "\n",
    "# train_idxs = np.linspace(0, 49, 50, dtype=int)\n",
    "train_folders = trial_folders#[trial_folders[i] for i in train_idxs]\n",
    "# test_folders = [trial_folders[i] for i in range(len(trial_folders)) if i not in train_idxs]\n",
    "\n",
    "\n",
    "thermal_file_name = \"Thermal_Camera\"\n",
    "num_samps_oversample = None # per experiment, number of samples to generate\n",
    "data_length = 9000\n",
    "fs = 30\n",
    "out_len = 9000 # sample length generated\n",
    "thermal_ext = \".npy\"\n",
    "\n",
    "dataset_thermal_train = CameraData(data_path, train_folders, thermal_file_name, num_samps_oversample, fs, data_length, out_len, thermal_ext)\n",
    "# dataset_thermal_test = CameraData(data_path, test_folders, thermal_file_name, num_samps_oversample, fs, data_length, out_len, thermal_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermal_vids = []\n",
    "dataset_thermal_train.get_vid = True\n",
    "for i in tqdm(range(len(dataset_thermal_train))):\n",
    "    # print(i)\n",
    "    thermal = dataset_thermal_train.__getitem__(i)\n",
    "    # frame = thermal[0,:,:]\n",
    "    thermal_vids.append(thermal)\n",
    "\n",
    "np.save(r\"F:\\OSA_local_version\\OSA_project\\Emir_Clean\\saved_data9000\\thermal_vids.npy\", np.array(thermal_vids))\n",
    "dataset_thermal_train.get_vid = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset_thermal_train.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_video(dataset_thermal_train, 3280, path=r\"F:\\OSA_local_version\\OSA_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_thermal_train.trial_folders[dataset_thermal_train.oversampling_idxs[3280][0]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_f=5e6\n",
    "freq_slope=60.012e12\n",
    "samples_per_chirp=256\n",
    "num_tx = 3\n",
    "num_rx = 4\n",
    "radar_file_name = \"FMCW_Radar.npy\"\n",
    "window_size = 15 # number of range bins to use\n",
    "\n",
    "dataset_radar_train = RFData(data_path, train_folders, data_length, radar_file_name, out_len, window_size, samples_per_chirp, samp_f, freq_slope, num_samps_oversample, num_tx, num_rx, fs)\n",
    "# dataset_radar_test = RFData(data_path, test_folders, data_length, radar_file_name, out_len, window_size, samples_per_chirp, samp_f, freq_slope, num_samps_oversample, num_tx, num_rx, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "vital_dict_file_name = \"gt_dict.pkl\"\n",
    "vital_key_radar = \"CHEST\"\n",
    "vital_key_thermal = \"AIR_flow\"\n",
    "l_freq_bpm = 5\n",
    "u_freq_bpm = 30\n",
    "dataset_OSA_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'OSA', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_CSA_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'CSA', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_MSA_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'MSA', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_hypopnea_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'Hypopnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_partial_apnea_train = SignalDataset(data_path, train_folders, vital_dict_file_name, 'Partial_Apnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "                              normalize=False)\n",
    "dataset_gt_thermal_train = SignalDataset(data_path, train_folders, vital_dict_file_name, vital_key_thermal, data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "dataset_gt_radar_train = SignalDataset(data_path, train_folders, vital_dict_file_name, vital_key_radar, data_length, out_len, True, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "\n",
    "# dataset_apnea_test = SignalDataset(data_path, test_folders, vital_dict_file_name, 'Sleep_Apnea', data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False,\n",
    "#                               normalize=False)\n",
    "# dataset_gt_thermal_test = SignalDataset(data_path, test_folders, vital_dict_file_name, vital_key_thermal, data_length, out_len, False, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)\n",
    "# dataset_gt_radar_test = SignalDataset(data_path, test_folders, vital_dict_file_name, vital_key_radar, data_length, out_len, True, fs, 1024, False, l_freq_bpm, u_freq_bpm, num_samps_oversample, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "fused_dataset_train = FuseDatasets([dataset_radar_train, dataset_thermal_train, dataset_gt_radar_train, dataset_gt_thermal_train, dataset_OSA_train, dataset_CSA_train, dataset_hypopnea_train, dataset_partial_apnea_train], [\"radar\", \"thermal\", \"gt_radar\", \"gt_ir\", \"gt_OSA\", \"gt_CSA\", \"hypopnea\", \"partial_apnea\"], out_len=out_len)\n",
    "# fused_dataset_test = FuseDatasets([dataset_radar_test, dataset_thermal_test, dataset_gt_radar_test, dataset_gt_thermal_test, dataset_apnea_test], [\"radar\", \"thermal\", \"gt_radar\", \"gt_ir\", \"gt_apnea\"], out_len=out_len)\n",
    "t_arr = np.linspace(0, out_len/fs, out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_idx_container = utils.get_patient_idxs(dataset_thermal_train, patient_ids=['v_12', 'v_13', 'v_20', 'v_29', 'v_30', 'v_32', 'v_36', 'v_37', 'v_39', 'v_40'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to save the index arrays\n",
    "folder_path = 'F:\\OSA_local_version\\OSA_project\\Emir_Clean\\patient_folder9000'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "patient_ids = ['v_12', 'v_13', 'v_20', 'v_29', 'v_30', 'v_32', 'v_36', 'v_37', 'v_39', 'v_40']\n",
    "for i, patient_id in enumerate(patient_ids):\n",
    "    patient_num = patient_id.split('_')[1]\n",
    "    idx_path = os.path.join(folder_path, f'patient_idxs_{patient_num}.npy')\n",
    "    np.save(idx_path, np.array(patient_idx_container[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "dataset = []\n",
    "gt_sigs = []\n",
    "for i in tqdm(range(len(fused_dataset_train))):\n",
    "    thermal = fused_dataset_train[i]['thermal']\n",
    "    thermal = utils.highpass_filter(thermal, fs=30, fc=0.1/2, order=6)\n",
    "    # thermal = signal.savgol_filter(thermal, 41, 3)\n",
    "    thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "    dataset.append(thermal)\n",
    "    gt_sigs.append(np.array([fused_dataset_train[i]['gt_ir'][:,0], fused_dataset_train[i]['gt_OSA'][:,0], fused_dataset_train[i]['gt_CSA'][:,0], fused_dataset_train[i]['gt_radar'][:,0], fused_dataset_train[i]['hypopnea'][:,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"F:\\OSA_local_version\\OSA_project\\Emir_Clean\\saved_data9000\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "np.save(os.path.join(path, r\"thermal_arr.npy\"), dataset)\n",
    "np.save(os.path.join(path, r\"gt_arr.npy\"), gt_sigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_arr = []\n",
    "for i in tqdm(range(len(fused_dataset_train))):\n",
    "    radar_data = fused_dataset_train[i]['radar']\n",
    "    power = []\n",
    "    filt_s = []\n",
    "    for k in range(15):\n",
    "        phase_signal = utils.unwrap_phase(radar_data[:, 0, 0, :, k])\n",
    "        filtered_x = utils.highpass_filter(phase_signal, order=6, fc=0.1/2, plot=False)\n",
    "        # filtered_x = signal.savgol_filter(filtered, 41, 3)\n",
    "        filtered_x = (filtered_x - np.mean(filtered_x)) / np.std(filtered_x)\n",
    "        filt_s.append(filtered_x)\n",
    "\n",
    "        f, Pxx_spec = signal.welch(filtered_x, fs, 'flattop', 1024, scaling='spectrum')\n",
    "        power.append(np.sqrt(Pxx_spec.max()))\n",
    "    radar_arr.append(filt_s[np.argmax(power)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(path, r\"radar_arr.npy\"), radar_arr)\n",
    "# radar_arr = np.load(r\"E:\\OSA_project\\Emir_Clean\\saved_idx\\radar_arrv5.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = []\n",
    "filt_s = []\n",
    "for i in range(25):\n",
    "\n",
    "        filtered = utils.highpass_filter(utils.normalize_signal(utils.unwrap_phase(radar_data[0,:, 0, 0, :, i].numpy())), order=6, fc=0.1/2, plot=False)\n",
    "        filtered_x = signal.savgol_filter(filtered, 41, 3)\n",
    "        filt_s.append(filtered_x)\n",
    "\n",
    "        f, Pxx_spec = signal.welch(filtered_x, fs, 'flattop', 1024, scaling='spectrum')\n",
    "        # plt.figure()\n",
    "        # plt.semilogy(f, np.sqrt(Pxx_spec))\n",
    "        # plt.xlabel('frequency [Hz]')\n",
    "        # plt.ylabel('Linear spectrum [V RMS]')\n",
    "        # plt.show()\n",
    "        print(np.sqrt(Pxx_spec.max()))\n",
    "        power.append(np.sqrt(Pxx_spec.max()))\n",
    "        print(i)\n",
    "        plt.plot(filtered_x, label='filtered')\n",
    "        plt.plot(gt_data[0,:,0], label='gt')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print(r\"##########################################\")\n",
    "print(np.argmax(power))\n",
    "plt.figure()\n",
    "plt.plot(filt_s[np.argmax(power)])\n",
    "plt.plot(gt_data[0,:,0], label='gt')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apnea_idx = []\n",
    "count = 0\n",
    "for i, data in tqdm(enumerate(fused_dataset_train)):\n",
    "    # print(i)\n",
    "    try:\n",
    "        batch = data['gt_CSA'][:,0]\n",
    "\n",
    "        if(np.mean(batch) > 0.1):\n",
    "            apnea_idx.append(i)\n",
    "            # patient_id = fused_dataset_train.trial_folders[fused_dataset_train.oversampling_idxs[i][0]]\n",
    "            # print(patient_id)\n",
    "    except:\n",
    "        count = count + 1\n",
    "        pass\n",
    "\n",
    "print(100*len(apnea_idx)/len(fused_dataset_train))\n",
    "print(count, len(apnea_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUKS_idx = []\n",
    "\n",
    "for i, data in tqdm(enumerate(fused_dataset_train)):\n",
    "    # print(i)\n",
    "    thermal = data['thermal']\n",
    "    thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "    if(utils.detect_NUKS(thermal) == True):\n",
    "        NUKS_idx.append(i)\n",
    "\n",
    "print(100*len(NUKS_idx)/len(fused_dataset_train))\n",
    "print(len(NUKS_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(path, r\"NUKS_idx.npy\"), NUKS_idx)\n",
    "# NUKS_idx = np.load(r\"E:\\OSA_project\\Emir_Clean\\saved_idx\\NUKS_idxv4.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_lock_idx = []\n",
    "dataset_thermal_train.get_vid = True\n",
    "for i in tqdm(range(len(dataset_thermal_train))):\n",
    "    # print(i)\n",
    "    thermal = dataset_thermal_train.__getitem__(i)\n",
    "    # frame = thermal[0,:,:]\n",
    "    for f_id in range(len(thermal)):\n",
    "        frame = thermal[f_id,:,:]\n",
    "        if((frame == frame[0,0]).all() == True):\n",
    "            mode_lock_idx.append(i)\n",
    "            break\n",
    "\n",
    "print(100*len(mode_lock_idx)/len(dataset_thermal_train))\n",
    "print(len(mode_lock_idx))\n",
    "dataset_thermal_train.get_vid = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(path, r\"mode_lock_idx.npy\"), mode_lock_idx)\n",
    "# mode_lock_idx = np.load(r\"E:\\OSA_project\\Emir_Clean\\saved_idx\\mode_lock_idxv4.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(NUKS_idx), len(mode_lock_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(NUKS_idx)):\n",
    "    if(NUKS_idx[i] in mode_lock_idx):\n",
    "        count = count + 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fused_dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "movement_idx = []\n",
    "vid_movement_idx = []\n",
    "for i in tqdm(range(len(fused_dataset_train))):\n",
    "    if(i in NUKS_idx):\n",
    "        # print(\"NUKS\")\n",
    "        pass\n",
    "    elif(i in mode_lock_idx):\n",
    "        # print('mode lock')\n",
    "        pass\n",
    "    else:\n",
    "        thermal = fused_dataset_train[i]['thermal']\n",
    "        thermal = utils.highpass_filter(thermal, fs=30, fc=0.1, order=2)\n",
    "        # thermal = signal.savgol_filter(thermal, 41, 3)\n",
    "        thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "\n",
    "        dists_min, dists_max, lmin, lmax = utils.movement_detector_radar(thermal, dmin=29, dmax=31, gt_breathing=fused_dataset_train[i]['gt_ir'][:,0], plot=False)\n",
    "        # print(i)\n",
    "        if((max(dists_min) > 4.5) or (max(dists_max) > 4.5)):\n",
    "            movement_idx.append(i)\n",
    "            # print('idx:', i, 'movement')\n",
    "        # dataset_thermal_train.get_vid = True\n",
    "        # if(utils.vid_movement_detector(dataset_thermal_train.__getitem__(i), lb=0, ub=200) == True):\n",
    "        #     vid_movement_idx.append(i)\n",
    "        #     print('idx:', i), 'video movement'\n",
    "        # dataset_thermal_train.get_vid = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(path,r\"movement_idx.npy\"), movement_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(fused_dataset_train))):\n",
    "    if(i in NUKS_idx):\n",
    "        # print(\"NUKS\")\n",
    "        pass\n",
    "    elif(i in mode_lock_idx):\n",
    "        # print('mode lock')\n",
    "        pass\n",
    "    else:\n",
    "        dataset_thermal_train.get_vid = True\n",
    "        if(utils.vid_movement_detector(dataset_thermal_train.__getitem__(i), lb=0, ub=200) == True):\n",
    "            vid_movement_idx.append(i)\n",
    "            # print('idx:', i), 'video movement'\n",
    "        dataset_thermal_train.get_vid = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movement_idx), len(vid_movement_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(path, r\"vid_movement_idx.npy\"), vid_movement_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in vid_movement_idx:\n",
    "    if(idx not in movement_idx):\n",
    "        print(idx) \n",
    "    thermal = fused_dataset_train[idx]['thermal']\n",
    "    thermal = utils.highpass_filter(thermal, fs=30, fc=0.1, order=2)\n",
    "    # thermal = signal.savgol_filter(thermal, 41, 3)\n",
    "    thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "    plt.plot(t_arr, fused_dataset_train[idx]['gt_ir'][:,0])\n",
    "    plt.plot(t_arr, fused_dataset_train[idx]['gt_CSA'][:,0], linewidth=7.0)\n",
    "    plt.plot(t_arr, fused_dataset_train[idx]['gt_OSA'][:,0], linewidth=7.0)\n",
    "\n",
    "    dists_min, dists_max, lmin, lmax = utils.movement_detector_radar(thermal, dmin=29, dmax=31, gt_breathing=fused_dataset_train[i]['gt_ir'][:,0], plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movement_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"E:\\OSA_project\\Emir_Clean\\saved_idx\\movement_idxv5.npy\", movement_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"F:\\OSA_local_version\\OSA_project\\Emir_Clean\\saved_idx\"\n",
    "NUKS_idx = np.load(os.path.join(path, r\"NUKS_idxv5.npy\"))\n",
    "mode_lock_idx = np.load(os.path.join(path, r\"mode_lock_idxv5.npy\"))\n",
    "movement_idx = np.load(os.path.join(path, r\"movement_idxv5.npy\"))\n",
    "vid_movement_idx = np.load(os.path.join(path, r\"vid_movement_idxv5.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "dataset = []\n",
    "gt_sigs = []\n",
    "for i in tqdm(range(len(fused_dataset_train))):\n",
    "    if(i in NUKS_idx):\n",
    "        # print(\"NUKS\")\n",
    "        pass\n",
    "    elif(i in mode_lock_idx):\n",
    "        # print('mode lock')\n",
    "        pass\n",
    "    elif(i in movement_idx):\n",
    "        # print('movement')\n",
    "        pass\n",
    "    elif(i in vid_movement_idx):\n",
    "        pass\n",
    "    else:\n",
    "        thermal = fused_dataset_train[i]['thermal']\n",
    "        thermal = utils.highpass_filter(thermal, fs=30, fc=0.1/2, order=6)\n",
    "        # thermal = signal.savgol_filter(thermal, 41, 3)\n",
    "        thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "        dataset.append(thermal)\n",
    "        gt_sigs.append(np.array([fused_dataset_train[i]['gt_ir'][:,0], fused_dataset_train[i]['gt_OSA'][:,0], fused_dataset_train[i]['gt_CSA'][:,0], fused_dataset_train[i]['gt_radar'][:,0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset), len(gt_sigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"E:\\OSA_project\\Emir_Clean\\saved_data\\thermal_arrv5.npy\", dataset)\n",
    "np.save(r\"E:\\OSA_project\\Emir_Clean\\saved_data\\gt_arrv5.npy\", gt_sigs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(100, len(next_movement_idx))):\n",
    "#     if(True):\n",
    "#         data = next_movement_idx[i]\n",
    "#         thermal = fused_dataset_train[data]['thermal']\n",
    "#         thermal = utils.highpass_filter(thermal, fs=30, fc=0.1, order=2)\n",
    "#         thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "#         dists_min, dists_max, lmin, lmax = utils.movement_detector(thermal, dmin=29, dmax=31, gt_breathing=fused_dataset_train[data]['gt_ir'][:,0], plot=True)\n",
    "#         plt.plot(t_arr, fused_dataset_train[data]['gt_OSA'][:,0])\n",
    "#         plt.plot(t_arr, fused_dataset_train[data]['gt_CSA'][:,0], linewidth = 7.0)\n",
    "#         plt.show()\n",
    "# for i in tqdm(range(0, len(movement_idx))):\n",
    "#     thermal = fused_dataset_train[movement_idx[i]]['thermal']\n",
    "#     thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "#     print('sample index: ', movement_idx[i])\n",
    "#     dists_min, dists_max, lmin, lmax = utils.movement_detector(thermal, dmin=29, dmax=31, gt_breathing=fused_dataset_train[movement_idx[i]]['gt_ir'][:,0], plot=True)\n",
    "#     plt.plot(t_arr, fused_dataset_train[movement_idx[i]]['gt_OSA'][:,0], linewidth=7.0, label='OSA')\n",
    "#     plt.plot(t_arr, fused_dataset_train[movement_idx[i]]['gt_CSA'][:,0])\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_arr = []\n",
    "prod_arr = []\n",
    "\n",
    "th_arr = np.linspace(0.1, 0.4, 15)\n",
    "window_size_arr = np.linspace(20,40, 10, dtype=int)\n",
    "modes = ['90th', 'max', 'median', 'mean']\n",
    "percentile = 50\n",
    "\n",
    "for th in tqdm(th_arr):\n",
    "    for window_max in tqdm(window_size_arr):\n",
    "        for window_min in window_size_arr:\n",
    "            for mode in modes:\n",
    "                gt_arr = []\n",
    "                pred_arr = []\n",
    "                \n",
    "\n",
    "                for idx in range(len(fused_dataset_train)):\n",
    "                    if((idx not in NUKS_idx) and (idx not in mode_lock_idx) and (idx not in movement_idx)):\n",
    "                        pred = utils.predict(fused_dataset_train[idx]['thermal'], dmin=window_min, dmax=window_max, th=th, mode=mode, percentage=percentile, plot=False)\n",
    "\n",
    "                        gt_OSA = fused_dataset_train[idx]['gt_OSA'][:,0]\n",
    "                        gt_CSA = fused_dataset_train[idx]['gt_CSA'][:,0]\n",
    "                        # gt_hp = gt_hypopnea[idx]\n",
    "\n",
    "                        if((np.mean(gt_OSA) > 0.1) or (np.mean(gt_CSA) > 0.1)):# or (np.mean(gt_hp) > 0.1)):\n",
    "                            gt_arr.append(1)\n",
    "                        else:\n",
    "                            gt_arr.append(0)\n",
    "                        \n",
    "                        if(np.mean(pred) > 0.1):\n",
    "                            pred_arr.append(1)\n",
    "                        else:\n",
    "                            pred_arr.append(0)\n",
    "                        \n",
    "                        # if(gt_arr[-1] != pred_arr[-1]):\n",
    "                        #     print(idx)\n",
    "                \n",
    "                        # AHI_arr.append(np.sum(pred_arr) / (1/60))\n",
    "                        # gt_AHI_arr.append(np.sum(gt_arr) / (1/60))\n",
    "\n",
    "                precision, recall, accuracy, confusion_matrix = utils.get_stats(np.array(pred_arr), np.array(gt_arr))\n",
    "                # print(\"Precision: \", precision, \"Recall: \", recall, \"Accuracy: \", accuracy, \"Confusion Matrix: \", confusion_matrix)\n",
    "                \n",
    "                prod_arr.append(precision*recall)\n",
    "                full_arr.append((th, mode, window_min, window_max, recall, precision, accuracy, confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in tqdm(enumerate(fused_dataset_train)):\n",
    "    # print(i)\n",
    "    batch = data['thermal']\n",
    "    thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "    if(utils.detect_NUKS(thermal) == True):\n",
    "        NUKS_idx.append(i)\n",
    "\n",
    "print(100*len(NUKS_idx)/len(fused_dataset_train))\n",
    "print(len(NUKS_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmax_func(lmax):\n",
    "    return(int(4*((len(lmax))/10)**(1/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = apnea_idx[3]\n",
    "for idx in apnea_idx:\n",
    "    thermal = fused_dataset_train[idx]['thermal']\n",
    "    thermal = (thermal - np.mean(thermal))/np.std(thermal)\n",
    "    pred = utils.predict(thermal, dmin=30, dmax=20, dmin_func=dmax_func, dmax_func=dmax_func, th=0.2, mode='max', percentage=25, interval=None, plot=True)\n",
    "    gt = fused_dataset_train[idx][\"gt_CSA\"][:,0]\n",
    "\n",
    "    print(utils.detect_NUKS(thermal))\n",
    "    # # print(utils.detect_mode_lock(fused_dataset_train, idx))\n",
    "    plt.plot(t_arr, gt, label='gt')\n",
    "    plt.plot(t_arr, pred, label='pred')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1) Implement the new motion detection algorithm for thermal\n",
    "# 1.2) Next steps is to finetune hyperparameters\n",
    "\n",
    "# 2.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read Kang Paper\n",
    "# 2. Get familiar with the thermal code\n",
    "# 3. visualize samples that the algorith gets wrong and change dmax, dmin func accordingly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = []\n",
    "filt_s = []\n",
    "idx = apnea_idx[15]\n",
    "radar_data = fused_dataset_train[idx]['radar']\n",
    "gt_radar = fused_dataset_train[idx]['gt_radar']\n",
    "gt = fused_dataset_train[idx][\"gt_CSA\"][:,0]\n",
    "\n",
    "for i in range(25):\n",
    "        radar_phase = utils.unwrap_phase(radar_data[:, 0, 0, :, i])\n",
    "        radar_phase = (radar_phase - np.mean(radar_phase)) / np.std(radar_phase)\n",
    "\n",
    "\n",
    "        filtered = utils.highpass_filter(radar_phase, order=6, fc=0.1/2, plot=False)\n",
    "        filtered_x = signal.savgol_filter(filtered, 41, 3)\n",
    "        filt_s.append(filtered_x)\n",
    "\n",
    "        f, Pxx_spec = signal.welch(filtered_x, fs, 'flattop', 1024, scaling='spectrum')\n",
    "        # plt.figure()\n",
    "        # plt.semilogy(f, np.sqrt(Pxx_spec))\n",
    "        # plt.xlabel('frequency [Hz]')\n",
    "        # plt.ylabel('Linear spectrum [V RMS]')\n",
    "        # plt.show()\n",
    "        # print(np.sqrt(Pxx_spec.max()))\n",
    "        power.append(np.sqrt(Pxx_spec.max()))\n",
    "        # print(i)\n",
    "        # plt.plot(filtered_x, label='filtered')\n",
    "        # plt.plot(gt_radar, label='gt')\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "        # print(r\"##########################################\")\n",
    "print(np.argmax(power))\n",
    "plt.figure()\n",
    "rad_sig = -filt_s[np.argmax(power)]\n",
    "rad_sig = (rad_sig - np.mean(rad_sig)) / np.std(rad_sig)\n",
    "plt.plot(t_arr, rad_sig)\n",
    "plt.plot(t_arr, gt_radar, label='gt')\n",
    "plt.plot(t_arr, gt)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dmax = int(2*((len(lmax))/17)**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path = r\"E:\\OSA_project\\gt_dict.pkl\"\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    gt_dict = pickle.load(f)\n",
    "\n",
    "print(gt_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = np.load(r\"E:\\OSA_project\\signal.npy\")\n",
    "gt_OSA = gt_dict['OSA']\n",
    "gt_CSA = gt_dict['CSA']\n",
    "gt_ir = gt_dict['AIR_flow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gt_ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1800*1\n",
    "thermal = signal[(start+0):(start+1800)]\n",
    "thermal = (thermal-np.mean(thermal))/np.std(thermal)\n",
    "plt.plot(thermal)\n",
    "plt.plot(utils.highpass_filter(thermal, fs=30, fc=0.1, order=2))\n",
    "plt.plot(gt_CSA[(start+0):(start+1800)])\n",
    "plt.plot(gt_OSA[(start+0):(start+1800)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hl_envelopes_idx(s, dmin_num=1, dmax_num=1, dmax_func=None, dmin_func=None, step_size=1, display=False):\n",
    "    \"\"\"\n",
    "    Input :\n",
    "    s: 1d-array, data signal from which to extract high and low envelopes\n",
    "    dmin, dmax: int, optional, size of chunks, use this if the size of the input signal is too big\n",
    "    split: bool, optional, if True, split the signal in half along its mean, might help to generate the envelope in some cases\n",
    "    Output :\n",
    "    lmin,lmax : high/low envelope idx of input signal s\n",
    "    \"\"\"\n",
    "    lmin = (np.diff(np.sign(np.diff(s))) > 0).nonzero()[0] + 1 \n",
    "    lmax = (np.diff(np.sign(np.diff(s))) < 0).nonzero()[0] + 1\n",
    "\n",
    "    dmin = dmin_num\n",
    "    dmax = dmax_num\n",
    "\n",
    "    if(dmax_func is not None):\n",
    "        dmax = dmax_func(lmax)\n",
    "\n",
    "    if(dmin_func is not None):\n",
    "        print('len(lmin): ', len(lmin), '\\n')\n",
    "        dmin = dmin_func(lmin)\n",
    "    \n",
    "    if(display == True):\n",
    "        print('len(lmax): ', len(lmax), '\\n')\n",
    "        print('len(lmin): ', len(lmin), '\\n')\n",
    "        print('step size: ', step_size, '\\n')\n",
    "\n",
    "    lmin = lmin[[max(i-dmin//2,0)+np.argmin(s[lmin[max(i-dmin//2,0):min(i+dmin//2,len(lmin))]]) for i in range(0,len(lmin),step_size)]]\n",
    "    lmax = lmax[[max(i-dmax//2,0)+np.argmax(s[lmax[max(i-dmax//2,0):min(i+dmax//2,len(lmax))]]) for i in range(0,len(lmax),step_size)]]\n",
    "    \n",
    "    return lmin,lmax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
